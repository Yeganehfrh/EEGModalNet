{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Hypnotic Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "import mne\n",
    "\n",
    "\n",
    "# helper functions\n",
    "def preprocess_data(data, baseline_mean):\n",
    "    # Step 1: Baseline correction (subtract the mean of the first 0.5 seconds for each channel) \n",
    "    data_corrected = data - baseline_mean\n",
    "    \n",
    "    # Step 2: Robust Scaler (normalize using median and IQR)\n",
    "    scaler = RobustScaler()\n",
    "    data_scaled = scaler.fit_transform(data_corrected.T)\n",
    "    \n",
    "    # Step 3: Normalization (z-score normalization)\n",
    "    normalizer = StandardScaler()\n",
    "    data_normalized = normalizer.fit_transform(data_scaled).T  # Transpose for sklearn, then back\n",
    "    \n",
    "    # Step 4: Clamp values greater than 20 standard deviations (becuause of the normalization at the previous step sd is 1)\n",
    "    std_threshold = 20\n",
    "    data_clamped = np.clip(data_normalized, -std_threshold, std_threshold)\n",
    "    \n",
    "    return data_clamped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_data_path = Path('/Volumes/Extreme SSD/PhD/OTKA study1/EEG data/BIDS/')\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "# is it because of the resampling that there are different number of timepoints?\n",
    "\n",
    "for root in sorted(EEG_data_path.glob('sub-*')):\n",
    "    sub_path  = root / 'ses-01/eeg/'\n",
    "    for data_path in sorted(sub_path.glob('*_eeg.vhdr')):\n",
    "        bids_id, task = re.match(r'.*/sub-(.*)_ses-01_task-(.*)_eeg.vhdr', str(data_path)).groups()\n",
    "        if task == 'baseline1':\n",
    "            print(f'>>>>>>Processing {bids_id} {task}')\n",
    "            epoch = mne.io.read_raw_brainvision(data_path, verbose=False, eog=['EOG1', 'EOG2'], misc=['ECG'])\n",
    "            epoch.pick(picks='eeg', exclude=['M1', 'M2'])\n",
    "            epoch.resample(128)\n",
    "            epoch = epoch.get_data()\n",
    "            baseline_mean = epoch.mean(axis=1, keepdims=True)\n",
    "            continue\n",
    "    \n",
    "        if task.__contains__('experience'):\n",
    "            print(f'>>>>>>Processing {bids_id} {task}')\n",
    "            epoch = mne.io.read_raw_brainvision(data_path, verbose=False, eog=['EOG1', 'EOG2'], misc=['ECG'])\n",
    "            epoch.pick(picks='eeg', exclude=['M1', 'M2'])\n",
    "            epoch.resample(128)\n",
    "            data = epoch.get_data()\n",
    "            data_clamped = preprocess_data(data, baseline_mean)\n",
    "            all_data[f'sub-{bids_id}_{task}'] = data_clamped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare the data to be converted and stored as a data array\n",
    "\n",
    "# trim all the data in the dictionary to the minimum length\n",
    "min_len = min([i.shape[1] for i in list(all_data.values())])\n",
    "all_data = {k: v[:, :min_len] for k, v in all_data.items()}\n",
    "\n",
    "# there are two missing tasks for sub-52, we fill them with zeros so th\n",
    "all_data['sub-52_experience2'] = np.zeros_like(all_data['sub-52_experience1'])\n",
    "all_data['sub-52_experience3'] = np.zeros_like(all_data['sub-52_experience1'])\n",
    "data = np.array(list(all_data.values()))\n",
    "data = data.reshape(52, 4, 56, -1)  # 52 subjects, 4 conditions, 56 channels, time\n",
    "# rearranging the data for the last participant whose experience 2 and 3 data is missing\n",
    "data[-1, -1] = data[-1, -3]  \n",
    "data[-1, -3] = data[-1, -2]\n",
    "\n",
    "data = xr.DataArray(data, \n",
    "                    dims=('subject', 'tasks', 'channel', 'time'),\n",
    "                    coords={'subject': np.unique([i.split('_')[0] for i in all_data.keys()]),\n",
    "                            'tasks': ['experience1', 'experience2', 'experience3', 'experience4'],\n",
    "                            'channel': epoch.ch_names,\n",
    "                            'time': np.arange(min_len)}\n",
    "                            )\n",
    "\n",
    "# data.to_netcdf('/Users/yeganeh/Codes/otka_data/EEG/experiment_EEG_data.nc5', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEGModalNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
