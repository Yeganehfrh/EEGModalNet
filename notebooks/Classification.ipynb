{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from typing import List\n",
    "import torch\n",
    "import keras\n",
    "import xarray as xr\n",
    "from src.EEGModalNet import WGAN_GP_old\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras import regularizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "\n",
    "DATA_PATH = 'data/LEMON_DATA/EC_all_channels_processed_downsampled.nc5'\n",
    "DEMOGRAPHICS_PATH = 'data/LEMON_DATA/Demographics.csv'\n",
    "PRETRAINED_CHECKPOINT_PATH = 'logs/06022025/06.02.2025_epoch_2500.model.keras'\n",
    "CLS_CHECKPOINT_PATH = 'logs/20.02.2025_classifier_v2'\n",
    "\n",
    "CHANNELS = ['O1', 'O2', 'F1', 'F2', 'C1', 'C2', 'P1', 'P2']\n",
    "\n",
    "DO_GROUPED_SHUFFLE = True\n",
    "DO_DOWN_SAMPLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xarray = xr.open_dataarray(DATA_PATH, engine='h5netcdf')\n",
    "n_subjects = xarray.subject.size\n",
    "\n",
    "demog = pd.read_csv(DEMOGRAPHICS_PATH, index_col=\"ID\")\n",
    "demog['is_old'] = demog['Age'].apply(lambda x:\n",
    "    2 if int(x.split('-')[0]) >= 50 else 1)\n",
    "\n",
    "is_old = demog.loc[xarray[\"subject\"].values, \"is_old\"]\n",
    "xarray[\"is_old\"] = xr.DataArray(is_old,dims='subject')\n",
    "\n",
    "if DO_DOWN_SAMPLE:\n",
    "    n_y0 = (is_old == 1).sum()\n",
    "    n_y1 = (is_old == 2).sum()\n",
    "    n_min = min(n_y0, n_y1)\n",
    "    n_subjects = n_min * 2\n",
    "    y0_sub_ids = is_old[is_old == 1].index[:n_min]\n",
    "    y1_sub_ids = is_old[is_old == 2].index[:n_min]\n",
    "    sub_ids = y0_sub_ids.append(y1_sub_ids).values\n",
    "    xarray = xarray.sel(subject=xarray.subject.isin(sub_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': np.float64(1.0), '1': np.float64(1.0)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def load_data(data_path: str,\n",
    "              channels: List[str],\n",
    "              bandpass_filter: float = .5,\n",
    "              time_dim: int = 512) -> tuple:\n",
    "\n",
    "    xarray = xr.open_dataarray(data_path, engine='h5netcdf')\n",
    "    n_subjects = xarray.subject.size\n",
    "\n",
    "    demog = pd.read_csv(DEMOGRAPHICS_PATH, index_col=\"ID\")\n",
    "    demog['is_old'] = demog['Age'].apply(lambda x:\n",
    "        2 if int(x.split('-')[0]) >= 50 else 1)\n",
    "\n",
    "    is_old = demog.loc[xarray[\"subject\"].values, \"is_old\"]\n",
    "    xarray[\"is_old\"] = xr.DataArray(is_old,dims='subject')\n",
    "\n",
    "    if DO_DOWN_SAMPLE:\n",
    "        n_y0 = (is_old == 1).sum()\n",
    "        n_y1 = (is_old == 2).sum()\n",
    "        n_min = min(n_y0, n_y1)\n",
    "        n_subjects = n_min * 2\n",
    "        y0_sub_ids = is_old[is_old == 1].index[:n_min]\n",
    "        y1_sub_ids = is_old[is_old == 2].index[:n_min]\n",
    "        sub_ids = y0_sub_ids.append(y1_sub_ids)\n",
    "        xarray = xarray.sel(subject=sub_ids)\n",
    "\n",
    "    x = xarray.sel(channel=channels)\n",
    "\n",
    "    x = x.to_numpy()\n",
    "    # n_subjects = x.shape[0]\n",
    "\n",
    "    if bandpass_filter is not None:\n",
    "        sos = butter(4, bandpass_filter, btype='high', fs=128, output='sos')  # TODO: fs\n",
    "        x = sosfiltfilt(sos, x, axis=-1)\n",
    "\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.tensor(x.copy()).unfold(2, time_dim, time_dim).permute(0, 2, 3, 1).flatten(0, 1)  # TODO: copy was added because of an error, look into this\n",
    "\n",
    "    sub = torch.tensor(np.arange(0, n_subjects).repeat(x.shape[0] // n_subjects)[:, np.newaxis])\n",
    "    labels = xarray.is_old.values - 1\n",
    "\n",
    "    y = labels.repeat(x.shape[0] / n_subjects)\n",
    "    sub_ids_classifier = sub.squeeze().numpy()\n",
    "\n",
    "    return x, y, sub_ids_classifier\n",
    "\n",
    "#\n",
    "X_input, y, groups = load_data(DATA_PATH, CHANNELS)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weights = {'0': class_weights[0], '1': class_weights[1]}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL AND EXTRACT X_EMBEDDING (X_e and X_e_subj)\n",
    "\n",
    "keras.utils.clear_session(free_memory=True)\n",
    "\n",
    "model = WGAN_GP_old(time_dim=512, feature_dim=len(CHANNELS),\n",
    "                    latent_dim=128, n_subjects=202,\n",
    "                    use_sublayer_generator=True,\n",
    "                    use_sublayer_critic=True,\n",
    "                    use_channel_merger_g=False,\n",
    "                    use_channel_merger_c=False,\n",
    "                    interpolation='bilinear')\n",
    "\n",
    "model.load_weights(PRETRAINED_CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "X_input_subj = model.critic.get_layer('torch_module_wrapper_1')(\n",
    "    X_input.float().to('mps'),\n",
    "    torch.tensor(groups).to('mps'))\n",
    "\n",
    "X_e = model.critic.model.get_layer('dis_flatten')(X_input)\n",
    "# X_e = model.critic.model.get_layer('dis_flatten')(X_input_subj)\n",
    "X_e = X_e.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.5),\n",
       " np.float64(0.4945054945054945),\n",
       " np.float64(0.5128205128205128))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPLIT\n",
    "\n",
    "if DO_GROUPED_SHUFFLE:\n",
    "    group_shuffle = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=1)\n",
    "    train_idx, val_idx = next(group_shuffle.split(X_e, y, groups=groups))\n",
    "else:\n",
    "    random_shuffle = ShuffleSplit(n_splits=1, test_size=0.3, random_state=1)\n",
    "    train_idx, val_idx = next(random_shuffle.split(X_e, y))\n",
    "\n",
    "y.mean(), y[train_idx].mean(), y[val_idx].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5076 - loss: 3.4917 - val_accuracy: 0.5210 - val_loss: 2.7848\n",
      "Epoch 2/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6405 - loss: 2.5518 - val_accuracy: 0.5385 - val_loss: 2.1542\n",
      "Epoch 3/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6863 - loss: 1.9440 - val_accuracy: 0.5430 - val_loss: 1.7284\n",
      "Epoch 4/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7298 - loss: 1.5346 - val_accuracy: 0.5599 - val_loss: 1.4557\n",
      "Epoch 5/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7558 - loss: 1.2687 - val_accuracy: 0.5633 - val_loss: 1.2868\n",
      "Epoch 6/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7792 - loss: 1.0870 - val_accuracy: 0.5607 - val_loss: 1.1886\n",
      "Epoch 7/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7880 - loss: 0.9759 - val_accuracy: 0.5669 - val_loss: 1.1311\n",
      "Epoch 8/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8059 - loss: 0.8967 - val_accuracy: 0.5664 - val_loss: 1.1036\n",
      "Epoch 9/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8106 - loss: 0.8374 - val_accuracy: 0.5618 - val_loss: 1.0846\n",
      "Epoch 10/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8299 - loss: 0.7788 - val_accuracy: 0.5751 - val_loss: 1.0781\n",
      "Epoch 11/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8309 - loss: 0.7504 - val_accuracy: 0.5740 - val_loss: 1.0956\n",
      "Epoch 12/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8473 - loss: 0.7116 - val_accuracy: 0.5655 - val_loss: 1.0903\n",
      "Epoch 13/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8539 - loss: 0.6843 - val_accuracy: 0.5714 - val_loss: 1.1221\n",
      "Epoch 14/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8599 - loss: 0.6768 - val_accuracy: 0.5652 - val_loss: 1.1272\n",
      "Epoch 15/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8670 - loss: 0.6624 - val_accuracy: 0.5827 - val_loss: 1.1506\n",
      "Epoch 16/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8830 - loss: 0.6254 - val_accuracy: 0.5759 - val_loss: 1.1477\n",
      "Epoch 17/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8812 - loss: 0.6099 - val_accuracy: 0.5838 - val_loss: 1.1604\n",
      "Epoch 18/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8813 - loss: 0.6123 - val_accuracy: 0.5762 - val_loss: 1.1806\n",
      "Epoch 19/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8833 - loss: 0.6077 - val_accuracy: 0.5864 - val_loss: 1.1943\n",
      "Epoch 20/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8872 - loss: 0.6027 - val_accuracy: 0.5864 - val_loss: 1.1862\n",
      "Epoch 21/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8965 - loss: 0.5678 - val_accuracy: 0.5835 - val_loss: 1.1742\n",
      "Epoch 22/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9127 - loss: 0.5395 - val_accuracy: 0.5923 - val_loss: 1.1715\n",
      "Epoch 23/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9182 - loss: 0.5252 - val_accuracy: 0.5954 - val_loss: 1.1955\n",
      "Epoch 24/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8803 - loss: 0.5957 - val_accuracy: 0.5799 - val_loss: 1.2661\n",
      "Epoch 25/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8730 - loss: 0.6232 - val_accuracy: 0.5816 - val_loss: 1.2523\n",
      "Epoch 26/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8856 - loss: 0.5992 - val_accuracy: 0.5864 - val_loss: 1.2302\n",
      "Epoch 27/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8981 - loss: 0.5760 - val_accuracy: 0.5886 - val_loss: 1.2069\n",
      "Epoch 28/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9157 - loss: 0.5417 - val_accuracy: 0.5819 - val_loss: 1.2240\n",
      "Epoch 29/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9157 - loss: 0.5257 - val_accuracy: 0.5855 - val_loss: 1.1918\n",
      "Epoch 30/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9260 - loss: 0.4866 - val_accuracy: 0.5866 - val_loss: 1.2169\n",
      "Epoch 31/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9381 - loss: 0.4671 - val_accuracy: 0.5886 - val_loss: 1.1874\n",
      "Epoch 32/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9357 - loss: 0.4618 - val_accuracy: 0.5883 - val_loss: 1.2164\n",
      "Epoch 33/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9335 - loss: 0.4591 - val_accuracy: 0.5847 - val_loss: 1.2251\n",
      "Epoch 34/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9263 - loss: 0.4719 - val_accuracy: 0.5872 - val_loss: 1.2311\n",
      "Epoch 35/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9251 - loss: 0.4717 - val_accuracy: 0.5900 - val_loss: 1.2509\n",
      "Epoch 36/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9282 - loss: 0.4757 - val_accuracy: 0.5948 - val_loss: 1.2195\n",
      "Epoch 37/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9280 - loss: 0.4767 - val_accuracy: 0.5976 - val_loss: 1.2553\n",
      "Epoch 38/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9215 - loss: 0.4912 - val_accuracy: 0.5943 - val_loss: 1.2833\n",
      "Epoch 39/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9075 - loss: 0.5093 - val_accuracy: 0.5920 - val_loss: 1.2869\n",
      "Epoch 40/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9193 - loss: 0.4925 - val_accuracy: 0.5999 - val_loss: 1.2402\n",
      "Epoch 41/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9362 - loss: 0.4653 - val_accuracy: 0.5971 - val_loss: 1.2079\n",
      "Epoch 42/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9363 - loss: 0.4602 - val_accuracy: 0.5976 - val_loss: 1.2860\n",
      "Epoch 43/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9358 - loss: 0.4660 - val_accuracy: 0.5928 - val_loss: 1.2669\n",
      "Epoch 44/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9434 - loss: 0.4522 - val_accuracy: 0.6016 - val_loss: 1.2707\n",
      "Epoch 45/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9486 - loss: 0.4387 - val_accuracy: 0.5900 - val_loss: 1.2463\n",
      "Epoch 46/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9410 - loss: 0.4401 - val_accuracy: 0.5892 - val_loss: 1.2912\n",
      "Epoch 47/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9398 - loss: 0.4433 - val_accuracy: 0.5937 - val_loss: 1.3154\n",
      "Epoch 48/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9376 - loss: 0.4444 - val_accuracy: 0.5926 - val_loss: 1.2812\n",
      "Epoch 49/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9391 - loss: 0.4442 - val_accuracy: 0.5917 - val_loss: 1.3201\n",
      "Epoch 50/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9327 - loss: 0.4533 - val_accuracy: 0.5872 - val_loss: 1.3060\n",
      "Epoch 51/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9392 - loss: 0.4428 - val_accuracy: 0.5926 - val_loss: 1.2965\n",
      "Epoch 52/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9420 - loss: 0.4382 - val_accuracy: 0.5948 - val_loss: 1.2925\n",
      "Epoch 53/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9478 - loss: 0.4290 - val_accuracy: 0.5900 - val_loss: 1.3197\n",
      "Epoch 54/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9365 - loss: 0.4462 - val_accuracy: 0.5895 - val_loss: 1.3464\n",
      "Epoch 55/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9320 - loss: 0.4653 - val_accuracy: 0.6038 - val_loss: 1.3056\n",
      "Epoch 56/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9320 - loss: 0.4625 - val_accuracy: 0.5912 - val_loss: 1.3543\n",
      "Epoch 57/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9430 - loss: 0.4472 - val_accuracy: 0.6021 - val_loss: 1.2687\n",
      "Epoch 58/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9528 - loss: 0.4186 - val_accuracy: 0.5993 - val_loss: 1.3064\n",
      "Epoch 59/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9517 - loss: 0.4192 - val_accuracy: 0.6041 - val_loss: 1.2790\n",
      "Epoch 60/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9428 - loss: 0.4396 - val_accuracy: 0.5951 - val_loss: 1.3537\n",
      "Epoch 61/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9431 - loss: 0.4382 - val_accuracy: 0.5923 - val_loss: 1.3206\n",
      "Epoch 62/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9413 - loss: 0.4318 - val_accuracy: 0.6030 - val_loss: 1.3111\n",
      "Epoch 63/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9586 - loss: 0.3999 - val_accuracy: 0.5962 - val_loss: 1.2854\n",
      "Epoch 64/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9566 - loss: 0.4043 - val_accuracy: 0.5948 - val_loss: 1.3226\n",
      "Epoch 65/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9520 - loss: 0.4074 - val_accuracy: 0.6013 - val_loss: 1.3024\n",
      "Epoch 66/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9564 - loss: 0.3936 - val_accuracy: 0.5996 - val_loss: 1.3395\n",
      "Epoch 67/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9608 - loss: 0.3803 - val_accuracy: 0.6013 - val_loss: 1.3001\n",
      "Epoch 68/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9606 - loss: 0.3792 - val_accuracy: 0.6007 - val_loss: 1.3081\n",
      "Epoch 69/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9700 - loss: 0.3550 - val_accuracy: 0.6036 - val_loss: 1.2944\n",
      "Epoch 70/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9655 - loss: 0.3597 - val_accuracy: 0.6137 - val_loss: 1.3052\n",
      "Epoch 71/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.3484 - val_accuracy: 0.5968 - val_loss: 1.3138\n",
      "Epoch 72/10000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9735 - loss: 0.3375 - val_accuracy: 0.5965 - val_loss: 1.3004\n",
      "Epoch 73/10000\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9805 - loss: 0.3179"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(f'{CLS_CHECKPOINT_PATH}.model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "    keras.callbacks.CSVLogger(f'{CLS_CHECKPOINT_PATH}.csv'),\n",
    "    keras.callbacks.TerminateOnNaN()\n",
    "]\n",
    "\n",
    "cls_model = keras.models.Sequential([   \n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "def smoothed_binary_crossentropy(epsilon=0.1): # Epsilon controls smoothing\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true_smoothed = y_true * (1.0 - epsilon) + 0.5 * epsilon # Soften labels\n",
    "        return keras.losses.binary_crossentropy(y_true_smoothed, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "cls_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    # loss=keras.losses.Hinge(),\n",
    "    # loss=smoothed_binary_crossentropy(),\n",
    "    # loss='mse',\n",
    "    # loss=keras.losses.BinaryFocalCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = cls_model.fit(\n",
    "    X_e[train_idx], y[train_idx],\n",
    "    epochs=10000,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_e[val_idx], y[val_idx]),\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    shuffle=True)\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(f'{CLS_CHECKPOINT_PATH}_final.csv')\n",
    "cls_model.save(f'{CLS_CHECKPOINT_PATH}_final.model.keras')\n",
    "\n",
    "clear_output(wait=True)\n",
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING LOSS AND ACCURACY\n",
    "\n",
    "def plot_history(history_df):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_df['loss'], label='train')\n",
    "    plt.plot(history_df['val_loss'], label='val')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_df['accuracy'], label='train')\n",
    "    plt.plot(history_df['val_accuracy'], label='val')\n",
    "    plt.legend()\n",
    "    plt.title('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEGModalNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
