{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from typing import List\n",
    "import torch\n",
    "import keras\n",
    "import xarray as xr\n",
    "from src.EEGModalNet import WGAN_GP_old\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras import regularizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "\n",
    "DATA_PATH = 'data/LEMON_DATA/EC_all_channels_processed_downsampled.nc5'\n",
    "CHECKPOINT_PATH = 'logs/06022025/06.02.2025_epoch_3000.model.keras'\n",
    "CHANNELS = ['O1', 'O2', 'F1', 'F2', 'C1', 'C2', 'P1', 'P2']\n",
    "\n",
    "DO_GROUPED_SHUFFLE = True\n",
    "DO_BALANCE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(data_path: str,\n",
    "              channels: List[str],\n",
    "              n_subjects: int = 202,\n",
    "              bandpass_filter: float = 1.0,\n",
    "              time_dim: int = 1024,\n",
    "              exclude_sub_ids=None) -> tuple:\n",
    "\n",
    "    xarray = xr.open_dataarray(data_path, engine='h5netcdf')\n",
    "    demog = pd.read_csv('data/LEMON_DATA/Demographics.csv', index_col=\"ID\")\n",
    "    demog['is_old'] = demog['Age'].apply(lambda x:\n",
    "        2 if int(x.split('-')[0]) >= 55 else 1)\n",
    "    is_old = demog.loc[xarray[\"subject\"].values, \"is_old\"]\n",
    "    xarray[\"is_old\"] = xr.DataArray(is_old, dims='subject')\n",
    "\n",
    "    x = xarray.sel(subject=xarray.subject[:n_subjects], channel=channels)\n",
    "\n",
    "    if exclude_sub_ids is not None:\n",
    "        x = x.sel(subject=~x.subject.isin(exclude_sub_ids))\n",
    "\n",
    "    x = x.to_numpy()\n",
    "    n_subjects = x.shape[0]\n",
    "\n",
    "    if bandpass_filter is not None:\n",
    "        sos = butter(4, bandpass_filter, btype='high', fs=128, output='sos')  # TODO: fs\n",
    "        x = sosfiltfilt(sos, x, axis=-1)\n",
    "\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.tensor(x.copy()).unfold(2, time_dim, time_dim).permute(0, 2, 3, 1).flatten(0, 1)  # TODO: copy was added because of an error, look into this\n",
    "\n",
    "    sub = torch.tensor(np.arange(0, n_subjects).repeat(x.shape[0] // n_subjects)[:, np.newaxis])\n",
    "    labels = xarray.is_old.values - 1\n",
    "    print(sub.shape, labels.shape)\n",
    "\n",
    "    y = labels.repeat(x.shape[0] // 202)\n",
    "    sub_ids_classifier = sub.squeeze().numpy()\n",
    "\n",
    "    return x, y, sub_ids_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "\n",
    "X_input, y, groups = load_data(DATA_PATH,\n",
    "                                channels=CHANNELS,\n",
    "                                n_subjects=202,\n",
    "                                bandpass_filter=0.5,\n",
    "                                time_dim=512,\n",
    "                                exclude_sub_ids=None)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weights = {'0': class_weights[0], '1': class_weights[1]}\n",
    "class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL AND EXTRACT X_EMBEDDING (X_e and X_e_subj)\n",
    "\n",
    "keras.utils.clear_session(free_memory=True)\n",
    "\n",
    "model = WGAN_GP_old(time_dim=512, feature_dim=len(CHANNELS),\n",
    "                    latent_dim=128, n_subjects=202,\n",
    "                    use_sublayer_generator=True,\n",
    "                    use_sublayer_critic=True,\n",
    "                    use_channel_merger_g=False,\n",
    "                    use_channel_merger_c=False,\n",
    "                    interpolation='bilinear')\n",
    "\n",
    "model.load_weights(CHECKPOINT_PATH)\n",
    "\n",
    "X_e = model.critic.model.get_layer('dis_flatten')(X_input)\n",
    "\n",
    "X_input_subj = model.critic.get_layer('torch_module_wrapper_1')(\n",
    "    X_input.float().to('mps'),\n",
    "    torch.tensor(groups).to('mps'))\n",
    "X_e_subj = model.critic.model.get_layer('dis_flatten')(X_input_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCE DATASET and SPLIT\n",
    "\n",
    "if DO_BALANCE:\n",
    "    y_df = pd.DataFrame(y, columns=['y'])\n",
    "    y0_size = y_df.query('y==0').shape[0]\n",
    "    y1_size = y_df.query('y==1').shape[0]\n",
    "\n",
    "    minority_size = min(y0_size, y1_size)\n",
    "\n",
    "    resample_idx = np.concatenate([\n",
    "        y_df.query('y==0').sample(minority_size, random_state=1).index.values,\n",
    "        y_df.query('y==1').sample(minority_size, random_state=1).index.values])\n",
    "\n",
    "    groups_resampled = groups[resample_idx]\n",
    "    X_e_resampled = X_e_subj[resample_idx].detach().cpu()\n",
    "    y_resampled = y[resample_idx]\n",
    "else:\n",
    "    groups_resampled = groups\n",
    "    X_e_resampled = X_e_subj.detach().cpu()\n",
    "    y_resampled = y\n",
    "\n",
    "\n",
    "# train/test split\n",
    "\n",
    "if DO_GROUPED_SHUFFLE:\n",
    "    group_shuffle = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=2)\n",
    "    train_idx, val_idx = next(group_shuffle.split(X_e_resampled, y_resampled, groups=groups_resampled))\n",
    "else:\n",
    "    random_shuffle = ShuffleSplit(n_splits=1, test_size=0.3, random_state=1)\n",
    "    train_idx, val_idx = next(random_shuffle.split(X_e_resampled, y_resampled))\n",
    "\n",
    "# y.mean(), y_resampled[train_idx].mean(), y_resampled[val_idx].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_model_path = 'logs/20.02.2025_classifier_v2'\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(f'{cls_model_path}.model.keras', monitor='val_accuracy', save_best_only=True),\n",
    "    keras.callbacks.CSVLogger(f'{cls_model_path}.csv'),\n",
    "    keras.callbacks.TerminateOnNaN()\n",
    "]\n",
    "\n",
    "cls_model = keras.models.Sequential([   \n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "def smoothed_binary_crossentropy(epsilon=0.1): # Epsilon controls smoothing\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true_smoothed = y_true * (1.0 - epsilon) + 0.5 * epsilon # Soften labels\n",
    "        return keras.losses.binary_crossentropy(y_true_smoothed, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "cls_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    # loss=keras.losses.Hinge(),\n",
    "    # loss=smoothed_binary_crossentropy(),\n",
    "    # loss='mse',\n",
    "    # loss=keras.losses.BinaryFocalCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = cls_model.fit(\n",
    "    X_e_resampled[train_idx], y_resampled[train_idx],\n",
    "    epochs=1000,\n",
    "    batch_size=20000,\n",
    "    validation_data=(X_e_resampled[val_idx], y_resampled[val_idx]),\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    shuffle=True)\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(f'{cls_model_path}_final.csv')\n",
    "cls_model.save(f'{cls_model_path}_final.model.keras')\n",
    "\n",
    "clear_output(wait=True)\n",
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING LOSS AND ACCURACY\n",
    "\n",
    "def plot_history(history_df):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_df['loss'], label='train')\n",
    "    plt.plot(history_df['val_loss'], label='val')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_df['accuracy'], label='train')\n",
    "    plt.plot(history_df['val_accuracy'], label='val')\n",
    "    plt.legend()\n",
    "    plt.title('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEGModalNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
