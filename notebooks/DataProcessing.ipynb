{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simsimd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msimsimd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RobustScaler, robust_scale\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# data directories\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simsimd'"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "from src.EEGNet.preprocessing import utils\n",
    "from pathlib import Path\n",
    "import re\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler, robust_scale\n",
    "\n",
    "# data directories\n",
    "data_path = f'/Volumes/Extreme SSD/PhD/MPI-LEMON/EEG_Raw_BIDS_ID/'\n",
    "mpi_path = f'/Volumes/EEG_MPILMBB_LEMON/EEG_Preprocessed_BIDS_ID/EEG_Preprocessed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which data are excluded from MPI dataset for processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all subject ids in preprocessed folder\n",
    "sub_ids_pro = []\n",
    "for subject_path in sorted(Path(mpi_path).glob('sub-*')):\n",
    "  sub_ids_pro.append(re.search('sub-(.*)_(.*)', subject_path.stem).group(1))\n",
    "sub_ids_pro = set(sub_ids_pro)  # drop duplicates\n",
    "\n",
    "# get all subject ids in raw folder\n",
    "sub_ids_raw = []\n",
    "for subject_path in sorted(Path(data_path).glob('sub-*')):\n",
    "  sub_ids_raw.append(re.search('sub-(.*)', subject_path.stem).group(1))\n",
    "sub_ids_raw = set(sub_ids_raw)  # drop any possible duplicates\n",
    "\n",
    "# find any ids in sub_ids_raw that are not in sub_ids_pro\n",
    "sub_ids_excluded = sorted(list(sub_ids_pro - sub_ids_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: delete the entire cell: Annotations & Data Segmentation\n",
    "### Data with different annotation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_annot_misbehave = {}\n",
    "sub_ids_raw = []\n",
    "for subject_path in sorted(Path(data_path).glob('sub-*')):\n",
    "  sub_id = subject_path.stem\n",
    "  sub_ids_raw.append(subject_path.stem)\n",
    "  raw = mne.io.read_raw_brainvision(data_path+f'/{sub_id}/RSEEG/{sub_id}.vhdr', verbose=False)\n",
    "  \n",
    "  # check annot names\n",
    "  points = utils.annotations_checker(raw.annotations.description.copy())\n",
    "\n",
    "  # save those with deflection\n",
    "  if sum(points.values()) != 2:\n",
    "     fnames_annot_misbehave[sub_id] = points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. segment and preprocess data with common annotation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids_normal = sorted(list(set(sub_ids_raw) - set(fnames_annot_misbehave.keys())))\n",
    "output_path = '/Volumes/Extreme SSD/PhD/MPI-LEMON/EEG_Raw_segmented/'\n",
    "rsfreq = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_id in sub_ids_normal[:5]:\n",
    "    raw = mne.io.read_raw_brainvision(data_path+f'/{sub_id}/RSEEG/{sub_id}.vhdr', verbose=False)\n",
    "    onsets, pattern = utils.find_pattern(raw)\n",
    "    raws = utils.segment_raw(raw, onsets, pattern, duration=60)\n",
    "\n",
    "    # save EC/EO segments in brainvision format\n",
    "    ## create subject folder\n",
    "    subject_path = output_path + sub_id\n",
    "    Path(subject_path).mkdir(parents=True, exist_ok=True)\n",
    "    ## downsample and save\n",
    "    for k in raws.keys():\n",
    "        raws[k].resample(rsfreq)\n",
    "        raws[k].export(subject_path + f'/{sub_id}_{k}.vhdr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. segment raw data with not common annotation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ1 = ['sub-010026']\n",
    "# an extera ''New Segment/', 'Comment/no USB Connection to actiCAP' markers in the beginning.\n",
    "\n",
    "typ2 = ['sub-010030']\n",
    "#an extera ''New Segment/', 'Comment/no USB Connection to actiCAP' markers in the beginning without extra switch markers.\n",
    "\n",
    "typ3 = ['sub-010062', 'sub-010064', 'sub-010134'] # only one switch markers in the beginning \n",
    "\n",
    "typ4 = ['sub-010191'] # an extra 'New Segment/' 'Comment/no USB Connection to actiCAP' 'Stimulus/S  1' markers in the beginning.\n",
    "\n",
    "typ5 = ['sub-010264'] # no switch markers in the beginning\n",
    "\n",
    "# ----------------------------------------------\n",
    "typ6 = ['sub-010126']\n",
    "# this subject there is no switch markers, and the annotation for eye closed is 'Stimulus/S208'\n",
    "\n",
    "# no switch markers in the annotations, and there is only two useless markers in the beginning\n",
    "typ7 = ['sub-010138', 'sub-010155', 'sub-010157',\n",
    "        'sub-010162', 'sub-010163', 'sub-010164', 'sub-010165',\n",
    "        'sub-010166', 'sub-010168', 'sub-010228', 'sub-010233',\n",
    "        'sub-010239', 'sub-010255', 'sub-010257', 'sub-010258',\n",
    "        'sub-010260', 'sub-010261', 'sub-010262', 'sub-010263',\n",
    "        'sub-010267', 'sub-010268', 'sub-010269', 'sub-010270',\n",
    "        'sub-010271', 'sub-010272', 'sub-010273', 'sub-010274',\n",
    "        'sub-010275', 'sub-010284', 'sub-010311', 'sub-010315',\n",
    "        'sub-010318']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data to eye closed and eye open segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the switch markers's onsets are the same as the beginning of the EC/EO segments\n",
    "sanity_check = {}\n",
    "all_eo = []\n",
    "all_ec = []\n",
    "subject_ids = []\n",
    "for subject_path in sorted(Path(data_path).glob('sub-*')):\n",
    "    sub_id = subject_path.stem\n",
    "    subject_ids.append(sub_id)\n",
    "    print('>>>>>>', sub_id)\n",
    "    raw = mne.io.read_raw_brainvision(data_path+f'/{sub_id}/RSEEG/{sub_id}.vhdr', verbose=False,\n",
    "                                      eog=['VEOG'])\n",
    "\n",
    "    # create a dictionary of annotations\n",
    "    desc = utils.change_annot_names(raw.annotations.description.copy(),\n",
    "                                    enumerated=True)\n",
    "    onsets = raw.annotations.onset.copy()\n",
    "    annot_dict = {k: v for k, v in zip(desc, onsets)}\n",
    "\n",
    "    # find the points where a switch between EC/EO happens\n",
    "    switch_onsets, switch_pattern = utils.find_switch_onset_pattern(annot_dict)\n",
    "    \n",
    "    # segment raw data based on switch points\n",
    "    raws = utils.segment_raw(raw, switch_onsets, switch_pattern, duration=60)\n",
    "    \n",
    "    # check if the segments are correct (only EC or EO in each segment)\n",
    "    for s in ['EC', 'EO']:\n",
    "        sanity_check[sub_id + '_' + s] = utils.check_segments(raws[s])\n",
    "    \n",
    "    raw_EO = raws['EO']\n",
    "    raw_EO = raw_EO.pick(picks='eeg')\n",
    "    \n",
    "    raw_EC = raws['EC']\n",
    "    raw_EC = raw_EC.pick(picks='eeg')\n",
    "    del raws\n",
    "    \n",
    "    all_eo.append(raw_EO.resample(128).get_data())\n",
    "    all_ec.append(raw_EC.resample(128).get_data())\n",
    "    \n",
    "# create a dataset\n",
    "ds = xr.Dataset({'eye_open': (['subject', 'channel', 'timestep'], all_eo),\n",
    "                 'eye_closed': (['subject', 'channel', 'timestep'], all_ec)},)\n",
    "\n",
    "# add subject ids to the dataset and save\n",
    "ds.coords['subject'] = subject_ids\n",
    "ds.to_netcdf('eeg_eo_ec.nc5', engine='h5netcdf')\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# clamp\n",
    "def clamp_eeg(data, axis=2, deviation=20):\n",
    "    \"\"\"Clamp EEG data proportional to the standard deviation of each channel.\"\"\"\n",
    "    # container for clamped data\n",
    "    data_clamped = np.zeros_like(data)\n",
    "    upper_dev = data.mean(axis=axis) + data.std(axis=axis) * deviation\n",
    "    lower_dev = data.mean(axis=axis) - data.std(axis=axis) * deviation\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            data_clamped[i, j, :] = np.clip(data[i, j, :], lower_dev[i, j], upper_dev[i, j])\n",
    "    return data_clamped\n",
    "\n",
    "def print_min_max(data, lower_dev, upper_dev, sub, channel):\n",
    "    \"\"\"Prints the min and max of a channel and checks if it would be clamped by the clamp_eeg function\n",
    "    This is used to check if the clamp function is working as expected.\"\"\"\n",
    "    if data[sub, channel, :].min() < lower_dev[sub, channel] or data[sub, channel, :].max() > upper_dev[sub, channel]:\n",
    "        print(f'Data: {sub}, {channel}: Min={data[sub, channel, :].min()}, Max={data[sub, channel, :].max()}',\n",
    "              f'Bounderies: Lower={lower_dev[sub, channel]}, Higher={upper_dev[sub, channel]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dataset\n",
    "da_name = 'eye_open'\n",
    "ds = xr.open_dataset('eeg_eo_ec.nc5', engine='h5netcdf')\n",
    "subject_ids = ds.subject.values\n",
    "da = ds[da_name]\n",
    "del ds\n",
    "\n",
    "# convert to numpy array\n",
    "data_eo = da.to_numpy()\n",
    "del da\n",
    "\n",
    "# baseline correction\n",
    "data_eo = data_eo - data_eo[:, :, :int(128*0.5)].mean(axis=2, keepdims=True)\n",
    "\n",
    "# save\n",
    "data_eo = xr.DataArray(data_eo, dims=['subject', 'channel', 'timestep'])\n",
    "data_eo.coords['subject'] = subject_ids\n",
    "data_eo.to_netcdf('eeg_EO_BaseCorr.nc5', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization & Clamping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open baseline corrected data\n",
    "da = xr.open_dataarray('eeg_EO_BaseCorr.nc5', engine='h5netcdf')\n",
    "da = da.sel(subject=da.subject.values[:5]).to_numpy()\n",
    "\n",
    "# normalize\n",
    "data = np.array(\n",
    "          [RobustScaler().fit_transform(da[i, :, :]) for i in range(da.shape[0])]\n",
    "        )\n",
    "print(data.min(), data.max())\n",
    "\n",
    "# clamp\n",
    "data_clamped = clamp_eeg(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "### Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simsimd\n",
    "\n",
    "# compute cosine similarity\n",
    "similarity_all = np.zeros((data_clamped.shape[0], 1830))  # 1830 is the lenght of the upper triangle of the similarity matrix\n",
    "for sub in range(data_clamped.shape[0]):\n",
    "    similarity = simsimd.cdist(data_clamped[sub, :, :], data_clamped[sub, :, :], metric='cosine')\n",
    "    similarity = similarity[np.triu_indices(similarity.shape[0], k=1)]\n",
    "    similarity_all[sub, :] = similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SugNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
