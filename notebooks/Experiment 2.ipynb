{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import mne\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, robust_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from data/test/sub-032301/RSEEG/sub-010002.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    }
   ],
   "source": [
    "# check the current working directory\n",
    "cwd = '/Users/yeganeh/Codes/EEGNet/'\n",
    "if os.getcwd() != cwd:\n",
    "    os.chdir(cwd)\n",
    "\n",
    "# channel names\n",
    "EEG = mne.io.read_raw_brainvision('data/test/sub-032301/RSEEG/sub-010002.vhdr', eog=['VEOG'])\n",
    "ch_names = EEG.info['ch_names']\n",
    "ch_names.remove('VEOG')\n",
    "del EEG\n",
    "\n",
    "# helper function to load the data\n",
    "# Helper functions\n",
    "# clamp\n",
    "def clamp_eeg(data, axis=1, deviation=20):\n",
    "    \"\"\"Clamp EEG data proportional to the standard deviation of each channel.\"\"\"\n",
    "    # container for clamped data\n",
    "    data_clamped = np.zeros_like(data)\n",
    "    upper_dev = data.mean(axis=axis) + data.std(axis=axis) * deviation\n",
    "    lower_dev = data.mean(axis=axis) - data.std(axis=axis) * deviation\n",
    "    for i in range(data.shape[0]):\n",
    "        data_clamped[i, :] = np.clip(data[i, :], lower_dev[i], upper_dev[i])\n",
    "    return data_clamped\n",
    "\n",
    "def print_min_max(data, lower_dev, upper_dev, sub, channel):\n",
    "    \"\"\"Prints the min and max of a channel and checks if it would be clamped by the clamp_eeg function\n",
    "    This is used to check if the clamp function is working as expected.\"\"\"\n",
    "    if data[sub, channel, :].min() < lower_dev[sub, channel] or data[sub, channel, :].max() > upper_dev[sub, channel]:\n",
    "        print(f'Data: {sub}, {channel}: Min={data[sub, channel, :].min()}, Max={data[sub, channel, :].max()}',\n",
    "              f'Bounderies: Lower={lower_dev[sub, channel]}, Higher={upper_dev[sub, channel]}')\n",
    "\n",
    "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
    "    ref_value = torch.tensor(ref)\n",
    "    amin = torch.tensor(amin)\n",
    "    log_spec = 10.0 * torch.log10(torch.maximum(amin, S))\n",
    "    log_spec -= 10.0 * torch.log10(torch.maximum(amin, ref_value))\n",
    "\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            raise ValueError(\"top_db must be non-negative\")\n",
    "        log_spec = torch.maximum(log_spec, log_spec.max() - top_db)\n",
    "\n",
    "    return log_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = xr.open_dataarray('data/baseline_corrected/eeg_EC_BaseCorr.nc5', engine='h5netcdf')\n",
    "subjects = data.subject.values[:50]\n",
    "\n",
    "# an xarray container for collecting procesed data across subjects\n",
    "processed_data = {}\n",
    "\n",
    "for sub in subjects:\n",
    "  print(f'Processing {sub}')\n",
    "  sub_data = data.sel(subject=sub).values\n",
    "\n",
    "  # normalize\n",
    "  sub_data = RobustScaler().fit_transform(sub_data)\n",
    "\n",
    "  # clamp\n",
    "  sub_data = clamp_eeg(sub_data)\n",
    "\n",
    "  processed_data[sub] = sub_data\n",
    "\n",
    "# save the processed data\n",
    "data = xr.DataArray(np.array(list(processed_data.values())),\n",
    "                    dims=('subject', 'channel', 'time'),\n",
    "                    coords={'subject': list(processed_data.keys()),\n",
    "                            'channel': ch_names})\n",
    "# data.to_netcdf('data/processed/normalized_clamped/eeg_EC_BaseCorr_Norm_Clamp_50.nc5', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "#### time-frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open processed eeg data\n",
    "DATA = xr.open_dataarray('data/processed/normalized_clamped/eeg_EC_BaseCorr_Norm_Clamp_50.nc5', engine='h5netcdf')\n",
    "subjects = DATA.subject.values\n",
    "\n",
    "tfrs = {}\n",
    "\n",
    "# morlet wavelet transform\n",
    "freqs = np.arange(3, 30, 2)  # TODO: I used 7 as the lower boundery but will change it to 3 as it is now\n",
    "n_cycles = [np.ceil(i) for i in freqs/(freqs[0]-2)]\n",
    "\n",
    "for sub in subjects:\n",
    "    print(f'Processing {sub}')\n",
    "    data_sub = DATA.sel(subject=sub).values\n",
    "    data_sub = np.expand_dims(data_sub, axis=0)  # add an additional dimension to the data\n",
    "    tfr = mne.time_frequency.tfr_array_morlet(data_sub, freqs=freqs, sfreq=128, n_cycles=n_cycles,\n",
    "                                              output='power',\n",
    "                                              n_jobs=-1, verbose=0)\n",
    "\n",
    "    # maybe only the spatial and frequency dimensions are important, so we can average over the time dimension\n",
    "    # Because our data is not time-locked!\n",
    "    tfrs[sub] = tfr.squeeze().mean(axis=-1)\n",
    "\n",
    "# convert the dictionary to a xarray\n",
    "tfrs = xr.DataArray(np.array(list(tfrs.values())),\n",
    "                    dims=('subject', 'channels', 'freqs'),\n",
    "                    coords={'subject': list(tfrs.keys()),\n",
    "                            'channels': ch_names,\n",
    "                            'freqs': freqs}\n",
    "                    )\n",
    "# save the tfrs\n",
    "tfrs.to_netcdf('data/TFR/tfrs.nc5', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Frequency-Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open tfrs\n",
    "tfrs = xr.open_dataarray('data/TFR/tfrs.nc5', engine='h5netcdf')\n",
    "subjects = tfrs.subject.values\n",
    "np.array(tfrs.min()), np.array(tfrs.max())\n",
    "\n",
    "for sub in subjects:\n",
    "    print(f'Processing {sub}')\n",
    "    tfr = tfrs.sel(subject=sub).values\n",
    "    tfr = power_to_db(torch.tensor(tfr))\n",
    "    min_max = (np.array(tfr.min()), np.array(tfr.max()))\n",
    "\n",
    "    # plot heatmap of the average power over time (frequency x channels)\n",
    "    plt.imshow(tfr, aspect='auto', origin='lower', cmap='jet')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # save the plot\n",
    "    plt.savefig(f'data/figures/tfr_heatmap_{sub}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 40, 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index of tfrs.max()\n",
    "idx = np.unravel_index(np.argmax(tfrs.values), tfrs.shape)\n",
    "idx\n",
    "\n",
    "# TODO: the reason for those high values in the data????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot topomap and use that as the input to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a epochs object\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=128, ch_types='eeg')\n",
    "epochs = mne.EpochsArray(data, info)\n",
    "\n",
    "pos = mne.channels.make_standard_montage('standard_1005')\n",
    "# add digitization points to the epoched data\n",
    "epochs.set_montage(pos)\n",
    "mne.viz.plot_tfr_topomap(tfr[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
