{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.preprocessing import utils\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# data directories\n",
    "data_path = f'/Volumes/Extreme SSD/PhD/MPI-LEMON/EEG_Raw_BIDS_ID/'\n",
    "mpi_path = f'/Volumes/EEG_MPILMBB_LEMON/EEG_Preprocessed_BIDS_ID/EEG_Preprocessed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which data are excluded from MPI dataset for processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all subject ids in preprocessed folder\n",
    "sub_ids_pro = []\n",
    "for subject_path in sorted(Path(mpi_path).glob('sub-*')):\n",
    "  sub_ids_pro.append(re.search('sub-(.*)_(.*)', subject_path.stem).group(1))\n",
    "sub_ids_pro = set(sub_ids_pro)  # drop duplicates\n",
    "\n",
    "# get all subject ids in raw folder\n",
    "sub_ids_raw = []\n",
    "for subject_path in sorted(Path(data_path).glob('sub-*')):\n",
    "  sub_ids_raw.append(re.search('sub-(.*)', subject_path.stem).group(1))\n",
    "sub_ids_raw = set(sub_ids_raw)  # drop any possible duplicates\n",
    "\n",
    "# find any ids in sub_ids_raw that are not in sub_ids_pro\n",
    "sub_ids_excluded = sorted(list(sub_ids_pro - sub_ids_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotations & Data Segmentation\n",
    "### Data with different annotation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_annot_misbehave = {}\n",
    "sub_ids_raw = []\n",
    "for subject_path in sorted(Path(data_path).glob('sub-*')):\n",
    "  sub_id = subject_path.stem\n",
    "  sub_ids_raw.append(subject_path.stem)\n",
    "  raw = mne.io.read_raw_brainvision(data_path+f'/{sub_id}/RSEEG/{sub_id}.vhdr', verbose=False)\n",
    "  \n",
    "  # check annot names\n",
    "  points = utils.annotations_checker(raw.annotations.description.copy())\n",
    "\n",
    "  # save those with deflection\n",
    "  if sum(points.values()) != 2:\n",
    "     fnames_annot_misbehave[sub_id] = points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. segment and preprocess data with common annotation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids_normal = sorted(list(set(sub_ids_raw) - set(fnames_annot_misbehave.keys())))\n",
    "output_path = '/Volumes/Extreme SSD/PhD/MPI-LEMON/EEG_Raw_segmented/'\n",
    "rsfreq = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_id in sub_ids_normal[:5]:\n",
    "    raw = mne.io.read_raw_brainvision(data_path+f'/{sub_id}/RSEEG/{sub_id}.vhdr', verbose=False)\n",
    "    onsets, pattern = utils.find_pattern(raw)\n",
    "    raws = utils.segment_raw(raw, onsets, pattern, duration=60)\n",
    "\n",
    "    # save EC/EO segments in brainvision format\n",
    "    ## create subject folder\n",
    "    subject_path = output_path + sub_id\n",
    "    Path(subject_path).mkdir(parents=True, exist_ok=True)\n",
    "    ## downsample and save\n",
    "    for k in raws.keys():\n",
    "        raws[k].resample(rsfreq)\n",
    "        raws[k].export(subject_path + f'/{sub_id}_{k}.vhdr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. segment raw data with not common annotation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_four = pd.DataFrame(fnames_annot_misbehave).T.query('all_same_type == True').index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sub-010126', 'sub-010138', 'sub-010155', 'sub-010157',\n",
       "       'sub-010162', 'sub-010163', 'sub-010164', 'sub-010165',\n",
       "       'sub-010166', 'sub-010168', 'sub-010228', 'sub-010233',\n",
       "       'sub-010239', 'sub-010255', 'sub-010257', 'sub-010258',\n",
       "       'sub-010260', 'sub-010261', 'sub-010262', 'sub-010263',\n",
       "       'sub-010267', 'sub-010268', 'sub-010269', 'sub-010270',\n",
       "       'sub-010271', 'sub-010272', 'sub-010273', 'sub-010274',\n",
       "       'sub-010275', 'sub-010284', 'sub-010311', 'sub-010315',\n",
       "       'sub-010318'], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fnames_annot_misbehave).T.query('all_same_type == False').index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_id in df[-7:]:\n",
    "    raw = mne.io.read_raw_brainvision(data_path+f'/{sub_id}/RSEEG/{sub_id}.vhdr', verbose=False)\n",
    "    print(f'>>>{sub_id}', utils.change_annot_names(raw.annotations.description.copy()), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ1 = ['sub-010026']\n",
    "# an extera ''New Segment/', 'Comment/no USB Connection to actiCAP' markers in the beginning.\n",
    "\n",
    "typ2 = ['sub-010030']\n",
    "#an extera ''New Segment/', 'Comment/no USB Connection to actiCAP' markers in the beginning without extra switch markers.\n",
    "\n",
    "typ3 = ['sub-010062', 'sub-010064', 'sub-010134'] # only one switch markers in the beginning \n",
    "\n",
    "typ4 = ['sub-010191'] # an extra 'New Segment/' 'Comment/no USB Connection to actiCAP' 'Stimulus/S  1' markers in the beginning.\n",
    "\n",
    "typ5 = ['sub-010264'] # no switch markers in the beginning\n",
    "\n",
    "# ----------------------------------------------\n",
    "typ6 = ['sub-010126']\n",
    "# this subject there is no switch markers, and the annotation for eye closed is 'Stimulus/S208'\n",
    "\n",
    "# no switch markers in the annotations, and there is only two useless markers in the beginning\n",
    "typ7 = ['sub-010138', 'sub-010155', 'sub-010157',\n",
    "        'sub-010162', 'sub-010163', 'sub-010164', 'sub-010165',\n",
    "        'sub-010166', 'sub-010168', 'sub-010228', 'sub-010233',\n",
    "        'sub-010239', 'sub-010255', 'sub-010257', 'sub-010258',\n",
    "        'sub-010260', 'sub-010261', 'sub-010262', 'sub-010263',\n",
    "        'sub-010267', 'sub-010268', 'sub-010269', 'sub-010270',\n",
    "        'sub-010271', 'sub-010272', 'sub-010273', 'sub-010274',\n",
    "        'sub-010275', 'sub-010284', 'sub-010311', 'sub-010315',\n",
    "        'sub-010318']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SugNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
